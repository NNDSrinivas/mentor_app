"""
Advanced AI Brain - Core Intelligence Engine
Inspired by Cluely's AI patterns and designed for comprehensive SDLC assistance.

This is the central intelligence that remembers everything and coordinates all actions.
"""
import asyncio
import json
import logging
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum

import openai
from .config import Config
from .persistent_memory import PersistentMemory
from .context_processor import ContextProcessor
from .meeting_intelligence import MeetingIntelligence
from .task_intelligence import TaskIntelligence
from .code_intelligence import CodeIntelligence

logger = logging.getLogger(__name__)

class ContextType(Enum):
    """Types of context the AI brain processes"""
    MEETING = "meeting"
    TASK = "task" 
    CODE = "code"
    DECISION = "decision"
    TEAM_MEMBER = "team_member"
    PROJECT = "project"
    BUILD = "build"
    PR_REVIEW = "pr_review"
    DOCUMENT = "document"

@dataclass
class AIDecision:
    """Represents a decision made by the AI brain"""
    decision_id: str
    decision_type: str
    context: Dict[str, Any]
    reasoning: str
    confidence: float
    user_confirmation_required: bool
    timestamp: str
    
@dataclass
class ActionPlan:
    """Represents an action plan generated by the AI"""
    plan_id: str
    title: str
    description: str
    steps: List[Dict[str, Any]]
    dependencies: List[str]
    estimated_time: int  # minutes
    confidence: float
    requires_user_approval: bool

class AIBrain:
    """
    Central AI Intelligence Engine
    
    This is the core brain that:
    - Remembers everything (meetings, tasks, code, decisions)
    - Understands context across the entire SDLC
    - Makes intelligent decisions with user confirmation
    - Coordinates all automated actions
    - Learns from user feedback and patterns
    """
    
    def __init__(self):
        self.memory = PersistentMemory()
        self.context_processor = ContextProcessor()
        self.meeting_intelligence = MeetingIntelligence(self)
        self.task_intelligence = TaskIntelligence(self) 
        self.code_intelligence = CodeIntelligence(self)
        
        # AI Models
        self.openai_client = openai.OpenAI(api_key=Config.OPENAI_API_KEY) if Config.OPENAI_API_KEY else None
        self.mock_mode = not Config.OPENAI_API_KEY
        
        # User context and preferences
        self.user_profile = {}
        self.user_preferences = {}
        self.active_projects = []
        self.current_context = {}
        
        # Decision tracking
        self.pending_decisions = []
        self.decision_history = []
        
        logger.info("🧠 AI Brain initialized - Ready for advanced SDLC assistance")
    
    async def process_context(self, context_type: ContextType, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process any type of context and generate intelligent insights
        This is the main entry point for all context processing
        """
        logger.info(f"🧠 Processing {context_type.value} context")
        
        try:
            # Store raw context in memory
            context_id = await self.memory.store_context(context_type, data)
            
            # Process context through appropriate intelligence module
            processed_data = await self._route_context_processing(context_type, data)
            
            # Generate insights and potential actions
            insights = await self._generate_insights(context_type, processed_data)
            
            # Update current context
            self.current_context[context_type.value] = {
                'context_id': context_id,
                'data': processed_data,
                'insights': insights,
                'timestamp': datetime.now().isoformat()
            }
            
            # Check for cross-context connections
            connections = await self._find_context_connections(context_type, processed_data)
            
            # Generate action recommendations
            actions = await self._generate_action_recommendations(context_type, processed_data, insights, connections)
            
            return {
                'context_id': context_id,
                'processed_data': processed_data,
                'insights': insights,
                'connections': connections,
                'recommended_actions': actions,
                'confidence': self._calculate_confidence(processed_data, insights)
            }
            
        except Exception as e:
            logger.error(f"❌ Error processing {context_type.value} context: {e}")
            return {'error': str(e), 'context_type': context_type.value}
    
    async def _route_context_processing(self, context_type: ContextType, data: Dict[str, Any]) -> Dict[str, Any]:
        """Route context to appropriate intelligence module"""
        
        if context_type == ContextType.MEETING:
            return await self.meeting_intelligence.process_meeting_context(data)
        elif context_type == ContextType.TASK:
            return await self.task_intelligence.process_task_context(data)
        elif context_type == ContextType.CODE:
            return await self.code_intelligence.process_code_context(data)
        else:
            # General context processing
            return await self.context_processor.process_general_context(context_type, data)
    
    async def _generate_insights(self, context_type: ContextType, processed_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate AI-powered insights from processed context"""
        
        if self.mock_mode:
            return {
                'summary': f"Mock insight for {context_type.value}",
                'key_points': ['Mock point 1', 'Mock point 2'],
                'confidence': 0.8
            }
        
        # Get related historical context
        related_context = await self.memory.get_related_context(context_type, processed_data)
        
        # Build comprehensive prompt
        prompt = self._build_insight_prompt(context_type, processed_data, related_context)
        
        try:
            response = await self.openai_client.chat.completions.acreate(
                model="gpt-4-turbo-preview",
                messages=[
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            insights = json.loads(response.choices[0].message.content)
            return insights
            
        except Exception as e:
            logger.error(f"❌ Error generating insights: {e}")
            return {'error': str(e)}
    
    async def _find_context_connections(self, context_type: ContextType, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Find connections between this context and existing knowledge"""
        
        connections = []
        
        # Find related meetings
        if context_type != ContextType.MEETING:
            related_meetings = await self.memory.find_related_meetings(data)
            connections.extend(related_meetings)
        
        # Find related tasks
        if context_type != ContextType.TASK:
            related_tasks = await self.memory.find_related_tasks(data)
            connections.extend(related_tasks)
        
        # Find related code/PRs
        if context_type != ContextType.CODE:
            related_code = await self.memory.find_related_code(data)
            connections.extend(related_code)
        
        return connections
    
    async def _generate_action_recommendations(self, context_type: ContextType, data: Dict[str, Any], 
                                             insights: Dict[str, Any], connections: List[Dict[str, Any]]) -> List[ActionPlan]:
        """Generate intelligent action recommendations"""
        
        recommendations = []
        
        # Meeting-specific actions
        if context_type == ContextType.MEETING:
            meeting_actions = await self.meeting_intelligence.generate_meeting_actions(data, insights, connections)
            recommendations.extend(meeting_actions)
        
        # Task-specific actions  
        elif context_type == ContextType.TASK:
            task_actions = await self.task_intelligence.generate_task_actions(data, insights, connections)
            recommendations.extend(task_actions)
        
        # Code-specific actions
        elif context_type == ContextType.CODE:
            code_actions = await self.code_intelligence.generate_code_actions(data, insights, connections)
            recommendations.extend(code_actions)
        
        return recommendations
    
    async def make_decision(self, decision_context: Dict[str, Any], require_user_confirmation: bool = True) -> AIDecision:
        """Make an intelligent decision with optional user confirmation"""
        
        decision = AIDecision(
            decision_id=f"decision_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            decision_type=decision_context.get('type', 'general'),
            context=decision_context,
            reasoning=await self._generate_decision_reasoning(decision_context),
            confidence=self._calculate_decision_confidence(decision_context),
            user_confirmation_required=require_user_confirmation,
            timestamp=datetime.now().isoformat()
        )
        
        if require_user_confirmation:
            self.pending_decisions.append(decision)
        else:
            self.decision_history.append(decision)
        
        await self.memory.store_decision(decision)
        return decision
    
    async def execute_action_plan(self, action_plan: ActionPlan, user_approved: bool = False) -> Dict[str, Any]:
        """Execute an action plan with proper confirmation flow"""
        
        if action_plan.requires_user_approval and not user_approved:
            logger.info(f"⏳ Action plan '{action_plan.title}' requires user approval")
            return {
                'status': 'pending_approval',
                'plan_id': action_plan.plan_id,
                'message': 'User approval required before execution'
            }
        
        logger.info(f"🚀 Executing action plan: {action_plan.title}")
        
        results = []
        for step in action_plan.steps:
            try:
                step_result = await self._execute_step(step)
                results.append({
                    'step': step,
                    'result': step_result,
                    'status': 'completed'
                })
            except Exception as e:
                logger.error(f"❌ Step failed: {step.get('description', 'Unknown step')}: {e}")
                results.append({
                    'step': step,
                    'error': str(e),
                    'status': 'failed'
                })
                break  # Stop on first failure
        
        # Store execution results
        await self.memory.store_action_execution(action_plan, results)
        
        return {
            'status': 'completed',
            'plan_id': action_plan.plan_id,
            'results': results,
            'success_rate': len([r for r in results if r.get('status') == 'completed']) / len(results)
        }
    
    async def _execute_step(self, step: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a single step in an action plan"""
        
        step_type = step.get('type')
        step_data = step.get('data', {})
        
        if step_type == 'code_generation':
            return await self.code_intelligence.generate_code(step_data)
        elif step_type == 'file_creation':
            return await self.code_intelligence.create_file(step_data)
        elif step_type == 'git_commit':
            return await self.code_intelligence.commit_changes(step_data)
        elif step_type == 'pr_creation':
            return await self.code_intelligence.create_pull_request(step_data)
        elif step_type == 'jira_update':
            return await self.task_intelligence.update_jira_task(step_data)
        elif step_type == 'documentation_update':
            return await self.code_intelligence.update_documentation(step_data)
        else:
            raise ValueError(f"Unknown step type: {step_type}")
    
    def _calculate_confidence(self, data: Dict[str, Any], insights: Dict[str, Any]) -> float:
        """Calculate confidence score for AI analysis"""
        # Base confidence
        confidence = 0.7
        
        # Adjust based on data quality
        if data.get('quality_score', 0) > 0.8:
            confidence += 0.1
        
        # Adjust based on historical context
        if insights.get('historical_context_available', False):
            confidence += 0.1
        
        # Adjust based on clarity of requirements
        if data.get('clarity_score', 0) > 0.7:
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def _calculate_decision_confidence(self, decision_context: Dict[str, Any]) -> float:
        """Calculate confidence for decision making"""
        # Similar to general confidence but decision-specific
        return self._calculate_confidence(decision_context, {})
    
    async def _generate_decision_reasoning(self, decision_context: Dict[str, Any]) -> str:
        """Generate human-readable reasoning for a decision"""
        if self.mock_mode:
            return f"Mock reasoning for decision based on {decision_context.get('type', 'general')} context"
        
        # Use AI to generate reasoning
        prompt = f"""
        Generate clear reasoning for this decision context:
        {json.dumps(decision_context, indent=2)}
        
        Provide concise, logical reasoning that a software engineer would understand.
        """
        
        try:
            response = await self.openai_client.chat.completions.acreate(
                model="gpt-4-turbo-preview",
                messages=[
                    {"role": "system", "content": "You are an AI assistant explaining decision reasoning clearly and concisely."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"❌ Error generating reasoning: {e}")
            return f"Decision based on {decision_context.get('type', 'general')} analysis"
    
    def _build_insight_prompt(self, context_type: ContextType, data: Dict[str, Any], related_context: List[Dict]) -> str:
        """Build comprehensive prompt for insight generation"""
        
        prompt = f"""
        Analyze this {context_type.value} context and provide structured insights:
        
        Current Context:
        {json.dumps(data, indent=2)}
        
        Related Historical Context:
        {json.dumps(related_context[:3], indent=2) if related_context else 'None'}
        
        Please provide insights in this JSON format:
        {{
            "summary": "Brief summary of the key information",
            "key_points": ["point 1", "point 2", "point 3"],
            "action_items": ["action 1", "action 2"],
            "risks": ["risk 1", "risk 2"],
            "opportunities": ["opportunity 1", "opportunity 2"],
            "recommendations": ["recommendation 1", "recommendation 2"],
            "confidence": 0.8
        }}
        """
        
        return prompt
    
    def _get_system_prompt(self) -> str:
        """Get system prompt for AI brain"""
        return """
        You are an advanced AI software engineering assistant with deep understanding of the SDLC.
        You have access to comprehensive context including meetings, tasks, code, and team dynamics.
        
        Your capabilities:
        - Analyze complex technical and business contexts
        - Make intelligent recommendations
        - Understand relationships between different aspects of software development
        - Provide clear, actionable insights
        
        Always provide structured, JSON-formatted responses when requested.
        Be precise, practical, and focused on helping software engineers be more productive.
        """
    
    async def get_current_state(self) -> Dict[str, Any]:
        """Get comprehensive current state of the AI brain"""
        return {
            'current_context': self.current_context,
            'pending_decisions': len(self.pending_decisions),
            'active_projects': self.active_projects,
            'user_profile': self.user_profile,
            'memory_stats': await self.memory.get_stats(),
            'last_activity': datetime.now().isoformat()
        }
    
    async def learn_from_feedback(self, feedback: Dict[str, Any]):
        """Learn from user feedback to improve future decisions"""
        await self.memory.store_feedback(feedback)
        
        # Adjust confidence and preferences based on feedback
        if feedback.get('rating', 0) >= 4:
            self.user_preferences[feedback.get('category', 'general')] = feedback.get('preferences', {})
        
        logger.info(f"📚 Learned from feedback: {feedback.get('category', 'general')}")
